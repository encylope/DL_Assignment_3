# DL_Assignment_3
Link to the report : https://api.wandb.ai/links/na21b075-indian-institute-of-technology-madras/qqmn8abm

Link to the Github repo: https://github.com/encylope/DL_Assignment_3

This repository contains the implementation and experiments for DL Assignment 3, where a sequence-to-sequence (Seq2Seq) model is trained to perform transliteration from Hindi script to Latin script using various RNN-based architectures.
## Task Overview

The task is to transliterate words from Roman script (transliterated Hindi) to Devanagari script using a character-level encoder-decoder architecture. Key techniques explored include:

Vanilla RNN, GRU, and LSTM architectures

Use of attention mechanisms

Beam search decoding

WandB for hyperparameter tuning

Visualization of model outputs 

## It contains

A3.ipynb -	Main Jupyter Notebook for training and evaluation

pred_attention.csv	- Model predictions with attention

pred_vanilla.csv	- Model predictions without attention

README.md	- This documentation file

